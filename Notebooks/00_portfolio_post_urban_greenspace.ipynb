{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Greenspace and Depression Prevalence in Denver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img\n",
    "        src=\"https://www.planetizen.com/files/styles/featured_large/public/images/Central%2070%20Covertop_003.jpg.webp?itok=GTYzjMbd\"\n",
    "        alt=\"Cover park over I-70 Denver, courtesy of Planetizen and CDOT (Nelson and Winling (2023))\" \n",
    "        height=\"600px\"/>\n",
    "    <figcaption aria-hidden=\"true\">\n",
    "        Cover park over I-70 Denver, courtesy of Planetizen and CDOT\n",
    "        (<span \n",
    "            class=\"citation\"\n",
    "            data-cites=\"Hanmson_2023\">\n",
    "            Hammon (2023)\n",
    "         </span>)\n",
    "    </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this project I will focus on Denver, Colorado, I will use health outcome data from the \n",
    "CDC, specifically % depression prevalence (using the wayback machine to acces the \n",
    "data that was taken down) as well as satellite based **multispectral** data for the \n",
    "City and County of Denver. This is to help answer the question of if vegetation related \n",
    "factors can predict % of depression prevalence by census tract.\n",
    "\n",
    "Denver, CO was chosen as the site of choice because I hope to use Denver as the site \n",
    "for the final project. Choosing Denver will help me get practice in the spectral data \n",
    "needed and see if it's something I can use or take pieces of for my final \n",
    "project. Additionally, I chose Phildelphia for the previous urban greenspace project in the \n",
    "fall course and wanted to choose a different city. I am most familiar with Denver and \n",
    "can use my existing knowledge of the city to guide any research and analyses.\n",
    "\n",
    "The health outcome factor of % depression prevalence was chosen because I have read\n",
    "articles previously on the effect that greenspace has on mental health in urban planning \n",
    "and I was curious on if a predictive model like OLS regression and computing error would \n",
    "show a predictive relationship between the two (Reklaitiene et al. 2014).\n",
    "\n",
    "Denver, like many other cities, has uneven access to urban green space that\n",
    "is rooted in racial discrimination and other injustices (Rigolon and Németh 2018). \n",
    "Redlining that took place in the 'New Deal Era' had lasting effects on the distribution \n",
    "of urban greenspace (Chen, Chavez-Norgaard, and University of Richmond 2025). One of these \n",
    "lasting effects is the 'inverted L' that will be disucessed further in the 'Site Desctiption' \n",
    "section below, but in short the inverted L examplfies a geographic divde in Denver \n",
    "that is tied to racial and socioeconomic factors (Sachs 2018). This context for the distribution \n",
    "of urban greenspaces in Denver will aid in conclusions of the predictive model (if vegetation \n",
    "related factors can predict % of depression prevalence by census tract).\n",
    "\n",
    "### Citations:\n",
    "\n",
    "* Chen, Victor, Stefan Chavez-Norgaard, and University of Richmond. 2025. “Mapping Inequality: Denver.” \n",
    "Mapping Inequality: Redlining in New Deal America. University of Richmond. 2025. \n",
    "https://dsl.richmond.edu/panorama/redlining/map/CO/Denver/context#loc=12/39.6994/-104.9581.\n",
    "\n",
    "* (Source of photo) Hammon, Mary. “Opening of Denver’s New Freeway Cap Park Triggers \n",
    "Gentrification Fears.” 2023. Planetizen.com. 2023. \n",
    "https://www.planetizen.com/news/2023/12/126716-opening-denvers-new-freeway-cap-park-triggers-gentrification-fears.\n",
    "\n",
    "* Reklaitiene, Regina, Regina Grazuleviciene, Audrius Dedele, Dalia Virviciute, Jone \n",
    "Vensloviene, Abdonas Tamosiunas, Migle Baceviciene, et al. 2014. “The Relationship of \n",
    "Green Space, Depressive Symptoms and Perceived General Health in Urban Population.” \n",
    "Scandinavian Journal of Public Health 42 (7): 669–76. https://doi.org/10.1177/1403494814544494.\n",
    "\n",
    "* Rigolon, Alessandro, and Jeremy Németh. 2018. “What Shapes Uneven Access to Urban \n",
    "Amenities? Thick Injustice and the Legacy of Racial Discrimination in Denver’s Parks.” \n",
    "Journal of Planning Education and Research 41 (3): 0739456X1878925.\n",
    "https://doi.org/10.1177/0739456x18789251.\n",
    "\n",
    "* Sachs, David. 2018. “This Shape Explains Denver’s Past, Present and Likely Its Future.” \n",
    "Denverite. December 21, 2018. https://denverite.com/2018/12/21/denver-socioeconomic-map-shape/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Description\n",
    "\n",
    "<figure>\n",
    "    <img\n",
    "        src=\"https://s3.amazonaws.com/holc/tiles/CO/Denver/1938/holc-scan.jpg\"\n",
    "        alt=\"Redlining map of Denver, CO courtesy of Mapping Inequality (Nelson and Winling (2023))\" \n",
    "        height=\"800px\"/>\n",
    "    <figcaption aria-hidden=\"true\">\n",
    "        Redlining map from Denver, CO courtesy of Mapping Inequality \n",
    "        (<span \n",
    "            class=\"citation\"\n",
    "            data-cites=\"nelson_mapping_2023\">\n",
    "            Nelson and Winling (2023)\n",
    "         </span>)\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "The map above is the Redlining Map of Denver and for basic orientation it shows the grid \n",
    "Denver is based on with 2 axes - going north to south is Broadway, and going west to east \n",
    "is Colfax (Nelson and Winling 2023). At the time the redlining maps were made (1935-1940) I-70 \n",
    "and I-25 were yet to be constructed, but where these end up going are clearly seen on the \n",
    "redlining map (Nelson and Winling 2023). I-25 runs north to south with a bit of a bend on \n",
    "the southern part; in the redlining map, I-25 would later start in the south east where \n",
    "there were already railroad tracks, then moves northwest to meet with the South Platte \n",
    "River, then moves northward alongside the river. I-70 would later cut through the Globeville, \n",
    "Elyeria, Swansia areas which were the 'hazardous' redlining grade, then went east along an \n",
    "existing road and railroad tracks, and went west along 48th Ave. Those areas that are on \n",
    "the west portion of I-70 were 'hazardous' and 'defiitely declining' redlining grades and \n",
    "the highway cut through pre-existing neighborhoods that were majority immigrant populated \n",
    "(Chen, Chavez-Norgaard, and University of Richmond 2025).\n",
    "\n",
    "<figure>\n",
    "    <img\n",
    "        src=\"https://denverite.com/cdn-cgi/image/width=3840,quality=75,format=auto/https://wp-denverite.s3.amazonaws.com/wp-content/uploads/sites/4/2018/12/181218-INVERTED-L-subsets.gif\"\n",
    "        alt=\"Series of 'inverted L' maps of Denver, CO courtesy of Denverite,\n",
    "        (Sources: Denver Office of Economic Development, Denver Parks and Recreation, United \n",
    "        States Census Bureau.)\" \n",
    "        height=\"500px\"/>\n",
    "    <figcaption aria-hidden=\"true\">\n",
    "        Series of 'inverted L' maps of Denver, CO courtesy of Denverite\n",
    "        (Sources: Denver Office of Economic Development, Denver Parks and Recreation, United \n",
    "        States Census Bureau.) \n",
    "        (<span \n",
    "            class=\"citation\"\n",
    "            data-cites=\"inverted_l_Sachs_Denverite_2018\">\n",
    "            Sachs 2018\n",
    "         </span>)\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Knowing the orientation of Denver and short context for how and why it is oreinted the way \n",
    "it is, is important for understanding the uneven distribution of urban greenspace and the \n",
    "signifcance behind that. Because parks were a large push of the City Beautiful Movement which \n",
    "was about increasing the city's prestige, the majority of the parks created were in upscale \n",
    "white neighborhoods that paid higher property taxes (Rigolon and Németh 2018). Denver currently \n",
    "has uneven access to urban greenspace that is rooted in racial discrimination and other \n",
    "injustices from redlining, gerrymandering, segregation, and racially restrictive covenants \n",
    "(Rigolon and Németh 2018). Some of the major or flagship parks in Denver are Cheeseman Park \n",
    "(just north of Colfax and just to the east of Broadway), Washington Park (slender rectangle \n",
    "south of Colfax), and City Park (north of Colfax, east of Broadway). All of those parks are \n",
    "inside the 'inverted L' which can be seen on the redlining map as well as the graphic above. \n",
    "Recently there was research showing that inside the 'inverted L' (east of I-25 and south of \n",
    "I-70) are predominately white, not vulnerable to displacement, more educated, and have more \n",
    "trees (Sachs 2018). Since the series of maps above were made, trees planted by the city are \n",
    "outside of the 'inverted L' (Sachs 2021). While there has been work to undo the inequitable \n",
    "effects redlining policies and create hopefully someday equal access and use to urban \n",
    "greenspace - to this day those flagship parks predominately still serve the city's most affluent \n",
    "groups of whom are White (Cernansky 2019). For this project, because the focus is on the \n",
    "relationship between a health outcome (% of depression prevalence) and urban greenspace, the \n",
    "idea or theory behind the 'inverted L' will guide further analyses to see first if vegetation \n",
    "related variables and % of depression prevalence have a predictive relationship and second if \n",
    "it does - does it follow the 'inverted L' pattern seen in socioeconomic related variables. \n",
    "\n",
    "### Citations:\n",
    "\n",
    "* Cernansky, Rachel. 2019. “Unequal Access to Parks in Denver Has Roots in \n",
    "History.” Collective Colorado. July 16, 2019. \n",
    "https://collective.coloradotrust.org/stories/unequal-access-to-parks-in-denver-has-roots-in-history/.\n",
    "\n",
    "* Chen, Victor, Stefan Chavez-Norgaard, and University of Richmond. 2025. “Mapping Inequality: Denver.” \n",
    "Mapping Inequality: Redlining in New Deal America. University of Richmond. 2025. \n",
    "https://dsl.richmond.edu/panorama/redlining/map/CO/Denver/context#loc=12/39.6994/-104.9581.\n",
    "\n",
    "* Nelson, Robert K, and LaDale Winling. 2023. “Mapping Inequality: Redlining in New Deal \n",
    "America.” In *American Panorama: An Atlas of United States History*, edited by Robert \n",
    "K Nelson and Edward L. Ayers. https://dsl.richmond.edu/panorama/redlining.\n",
    "\n",
    "* Rigolon, Alessandro, and Jeremy Németh. 2018. “What Shapes Uneven Access to Urban \n",
    "Amenities? Thick Injustice and the Legacy of Racial Discrimination in Denver’s Parks.” \n",
    "Journal of Planning Education and Research 41 (3): 0739456X1878925. \n",
    "https://doi.org/10.1177/0739456x18789251.\n",
    "\n",
    "* Sachs, David. 2018. “This Shape Explains Denver’s Past, Present and Likely Its Future.” \n",
    "Denverite. December 21, 2018. https://denverite.com/2018/12/21/denver-socioeconomic-map-shape/.\n",
    "\n",
    "* Sachs, David. 2021. “How Denver Is Chipping Away at the Inverted L: Housing and Trees Edition.” \n",
    "Denverite. April 7, 2021. \n",
    "https://denverite.com/2021/04/07/how-denver-is-chipping-away-at-the-inverted-l-housing-and-trees-edition/.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * **CDC Places Data**\n",
    "\n",
    "<figure>\n",
    "    <img\n",
    "        src=\"https://archive.org/offshoot_assets/assets/ia-logo-2c2c2c.03bd7e88c8814d63d0fc..svg\"\n",
    "        alt=\" Internet Archive Logo courtesy of the Internet Archive (Internet Archive 2014)\" \n",
    "        height=\"300px\"/>\n",
    "     <img\n",
    "        src=\"/Users/briannagleason/Documents/earth-analytics/urban_greenspace_denver/urban_greenspace_denver/Notebooks/CDC_internet_archive.png\"\n",
    "        alt=\"Screenshot of CDC datasets page of the Internet Archive, courtesy of the Internet Archive\n",
    "        (Internet Archieve )\" \n",
    "        height=\"500px\"/>\n",
    "    <figcaption aria-hidden=\"true\">\n",
    "        Internet Archive logo and screenshot of CDC datasets page courtesy of Internet Archive \n",
    "        (<span \n",
    "            class=\"citation\"\n",
    "            data-cites=\"internet_archive\">\n",
    "            Internet Archive 2014 (left) and Centers for Disease Control and Prevention via Internet Archive 2025 (right)\n",
    "         </span>)\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "#### CDC Places Data (prior to it being taken down)\n",
    "\n",
    "CDC Places prior to 2020 was known as 500 Cities, so instead of having full \n",
    "coverage across the US including rural areas, it only included 500 cities (CDC 2021, \n",
    "\"About the Places Project\"). While in this phase, the datasets also only included \n",
    "chronic diseases (CDC 2021, \"About the Places Project\"). Since 2020 it has expanded \n",
    "the measures included in the datasets, and these measures included, are increasing \n",
    "each year the datasets are released (CDC 2021, \"Measure Definitions\"). It appears new \n",
    "sets of data are released every year rather than old/ previous years' datasets being \n",
    "updated (CDC 2021, \"About the Places Project\"). \n",
    "\n",
    "If curious about the methodology that CDC Places uses and how the data is validated, \n",
    "please visit [CDC Places methodology](https://www.cdc.gov/places/methodology/index.html).\n",
    "*(Since writing this, this page has been taken down, keeping for purposes of retaining \n",
    "information).*\n",
    "\n",
    "Due this being realted to the Census, which is only done every 10 years, also \n",
    "affects this data in that prior research will need to be done to see what year \n",
    "of the Census the CDC Places data is using (CDC 2021, \"About the Places Project\"). \n",
    "For example, the 2024 CDC Places data is using the 2020 Census, not the 2010 Census \n",
    "like the prior years of the CDC Places data (CDC 2021, \"About the Places Project\"). \n",
    "These datasets also differ by geography type or administrative boundaries (CDC 2021, \n",
    "\"About the Places Project\"). While this project is using Census Tracts as the boundary, \n",
    "there are other options available like U.S. counties, census designated places, and \n",
    "ZIP Code Tabulation Areas (ZCTA's) (CDC 2021, \"PLACES\"). Depending on the goal of a \n",
    "project would likely change the geography being used. CDC Places data includes all \n",
    "areas of the United States with 50 or more adult residents (CDC 2021, \"About the \n",
    "Places Project\").\n",
    "\n",
    "Prior to the CDC data being taken down, the data was free to access which contributed \n",
    "to Open Data Science efforts. The data was considered public domain and did not require \n",
    "or have a specific license to use or manipulate the data as of 2/2/2025.\n",
    "\n",
    "*(Prior to 2/2/2025)* The data itself could be accessed in multiple formats icnluding \n",
    "JSON, GeoJSON (which is what I used), CSV if getting via API. Or, if downloading it can \n",
    "be accessed in even more formats including those listed prior and many others (CDC 2021, \n",
    "\"PLACES\"). This is worth exploring and considering depending on what project \n",
    "the data is being used for and how the data will be used. *As of 2/20/2025* I was able to \n",
    "call the CDC API to get the census tracts associated with the CDC places data without issue; \n",
    "however, once I got to the downloading the health outcome data like asthma, depression, stroke, \n",
    "etc. I wasn't able to access it via the same API call. Instead, I used the *Internet Archive* \n",
    "to access data that was previously available on the CDC website (CDC 2025, (Internet \n",
    "Archive - CDC Datasets)). \n",
    "\n",
    "#### CDC Places Data (via the Internet Archive)\n",
    "\n",
    "The Internet Archive is a non-profit that has been archiving websites and other digital \n",
    "assests since 1996 (Internet Archive 2009). What they archieve is quite vast including: \n",
    "webpages, books/texts, audio recording, videos (including tv news), images, software, etc.\n",
    "(Internet Archive 2009). They have many different orgnaizations which fund them including \n",
    "the American Library Association and the Biodiversity Heritage Library (Internet Archive 2009).\n",
    "This is free to use and access, their goal is to make knowledge publicly accessible, there \n",
    "is one exception and its for books made after 1928 can be borrowed (Internet Archive 2009). \n",
    "So this also contributes to Open Science efforts and does not have a particular liecence \n",
    "to access the information the Internet Archive has (Internet Archive 2009)\n",
    "\n",
    "Anything can be searched in the 'Wayback Machine', their searchbar, looking for a website, book, \n",
    "any of the formats listed previously and it will return many results that will take time to sift \n",
    "through to find what you are looking for (Internet Archive 2014). For this project the focus is \n",
    "the CDC datasets which were taken off the CDC website around January 31st. I was able to access \n",
    "the CDC dataset 2/2/2025 via API call but was unable to call the API after that for the CSV data \n",
    "about health outcomes. This led me to the Internet Archive to access this data that was taken down.\n",
    "\n",
    "The CDC datasets saved on the Internet Archive are set up differently, and organized by type of CDC \n",
    "dataset, so I navigated to the comma-separated values (csv) because I needed a csv file to merge \n",
    "the depression data with the geometry of the census tracts. There are *a ton* (2000+) of different \n",
    "CSV datasets available here; there's everything from COVID-19 data, impaired driving deaths, \n",
    "medicaid coverage, the 'Places' data (which is what I needed) and so on (CDC 2025, (Internet \n",
    "Archive - CDC Datasets)). I used the url for - \n",
    "\"PLACES_Local_Data_for_Better_Health_Census_Tract_Data_2022_release.csv\" because I needed the \n",
    "'Places - local data for better health' for census tracts and chose 2022 because it only had 512M\n",
    "versus 2023 has 617M and 2024 has 726M (CDC 2025, (Internet Archive - CDC Datasets)). Even though \n",
    "I ended up using an API call, the issue was that I knew I would need to download the entire dataset \n",
    "to see what I was working with to set up the API call with the correct spelling/capitalization/etc. \n",
    "I was more comfortable with downloading the 512M than the higher amounts. There was an available \n",
    "metadata csv to download on the Internet Archive as well; however I downloaded it and it didn't tell \n",
    "me the names of columns or anything that would help with the API call (CDC 2025, (Internet Archive - \n",
    "CDC Datasets)). In looking at the downloaded dataset, the data was actually from a mix of years, mainly \n",
    "2020, but also had some (very few rows) of 2021 and 2022; it also had different capitalization and names \n",
    "for the columns than what the original CDC dataset had. All of this should be kept in mind if you are \n",
    "using the Internet Archive for a dataset but previously had access to the original format. \n",
    "The datasets might be set up differently and while there is data there, it may not be exactly what it \n",
    "was when it was queryed or called through the original source. Despite these complications, I am very \n",
    "grateful that this dataset, as well as all the other CDC datasets are still accessible via the Internet \n",
    "Archive. There are other entities, mostly private or non-profit that have also secured those CDC datasets, \n",
    "so it is possible to find the datasets a different way, but that would likely take more digging and \n",
    "possibly requesting the data instead of anytime access to the Internet Archive.\n",
    "\n",
    "\n",
    "### CDC Places Citations:\n",
    "\n",
    "* CDC Places data accessed previously - https://data.cdc.gov/resource/cwsq-ngmh.geojson\n",
    "*(Since writing this, this page has been taken down, keeping for purposes of retaining information).*\n",
    "\n",
    "* Center for Disease Control and Prevention (CDC). 2020. “PLACES Methodology.” \n",
    "Centers for Disease Control and Prevention. December 8, 2020. \n",
    "https://www.cdc.gov/places/methodology/index.html.\n",
    "*(Since writing this, this page has been taken down, keeping for purposes of retaining information).*\n",
    "\n",
    "* Center for Disease Control and Prevention (CDC). 2021. “About the PLACES Project.” \n",
    "Centers for Disease Control and Prevention. October 18, 2021.\n",
    "https://www.cdc.gov/places/about/index.html.\n",
    "*(Since writing this, this page has been taken down, keeping for purposes of retaining information).*\n",
    "\n",
    "* Centers for Disease Control and Prevention (CDC). 2021. “Measure Definitions.” \n",
    "Centers for Disease Control and Prevention. October 18, 2021. \n",
    "https://www.cdc.gov/places/measure-definitions/index.html.\n",
    "*(Since writing this, this page has been taken down, keeping for purposes of retaining information).*\n",
    "\n",
    "* Centers for Disease Control and Prevention (CDC). 2021. “PLACES: Local Data \n",
    "for Better Health.” Centers for Disease Control and Prevention. March 8, 2021. \n",
    "https://www.cdc.gov/PLACES.\n",
    "Data initially Accessed via API [2/2/2025]\n",
    "*(Since writing this, this page has been taken down, keeping for purposes of retaining information).*\n",
    "\n",
    "* Centers for Disease Control and Prevention (CDC). 2024. “Data | Centers for Disease Control \n",
    "and Prevention.” Data.CDC.gov. 2024. \n",
    "https://data.cdc.gov/browse?category=500+Cities+%26+Places&q=2024&sortBy=relevance&tags=places.\n",
    "(*Note - this link takes you too all the localties and verstions avialable not \n",
    "the specific one used here).\n",
    "*(Since writing this, this page has been taken down, keeping for purposes of retaining information).*\n",
    "\n",
    "* Centers for Disease Control and Prevention (CDC). 2025. “CDC Datasets Uploaded before January \n",
    "28th, 2025 : Centers for Disease Control and Prevention : Free Download, Borrow, and \n",
    "Streaming : Internet Archive.” Internet Archive - CDC Datasets. January 28, 2025. \n",
    "https://archive.org/details/20250128-cdc-datasets.\n",
    "\n",
    "* Internet Archive. 2009. “About the Internet Archive.” Archive.org. 2009. \n",
    "https://archive.org/about/.\n",
    "\n",
    "* Internet Archive. 2014. “Internet Archive.” Archive.org. 2014. https://archive.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * **NAPI via Microsoft Planetary Computer STAC API - Multispectral Data**\n",
    "\n",
    "<figure>\n",
    "    <img\n",
    "        src=\"https://miro.medium.com/v2/resize:fit:1400/0*HMIm8zbhr02-DvT1.png\"\n",
    "        alt=\"Graphic of Microsoft Planetary Computer (GeoNext and Halder 2024)\" \n",
    "        height=\"275px\"/>\n",
    "    <img\n",
    "        src=\"https://d9-wret.s3.us-west-2.amazonaws.com/assets/palladium/production/s3fs-public/styles/full_width/public/thumbnails/image/dmidhoover2008to2012.JPG?itok=Aw7_kIjh\"\n",
    "        alt=\" 'Series of High Resolution Orthoimagery (2008, 2010, and 2012) of the \n",
    "        Hoover Dam BypassProject.' (United States Geological Survey (USGS) - \n",
    "        Earth Resources Observation and Science (EROS) Center 2018) \" \n",
    "        height=\"300px\"/>\n",
    "    <figcaption aria-hidden=\"true\">\n",
    "        Graphic of Microsoft Planetary Computer (GeoNext and Halder 2024)(top),\n",
    "        \"Series of High Resolution Orthoimagery (2008, 2010, and 2012) of the \n",
    "        Hoover Dam BypassProject.\"(United States Geological Survey (USGS) - \n",
    "        Earth Resources Observation and Science (EROS) Center 2018) (bottom)\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "The data source that will be used for the urban green space element of this project \n",
    "is NAIP (National Agricultural Imagery Program) (United States Geological Survey \n",
    "(USGS) - Earth Resources Observation and Science (EROS) Center, n.d.). The NAIP \n",
    "data can be used for many things beyond what this case study aims to do, in fact \n",
    "it is usually used for agriculture and it is worth exploring if it is applicable or \n",
    "useful in other projects, agriculture related and beyond (United States Geological \n",
    "Survey (USGS) - Earth Resources Observation and Science (EROS) Center, n.d.). NAIP is \n",
    "aerial imagery that has a 1m resolution and has coverage for the continental U.S. with \n",
    "either red, blue, green bands, or near infrared, red, green, and blue bands \n",
    "(United States Geological Survey (USGS) -Earth Resources Observation and Science \n",
    "(EROS) Center, n.d.). Similar to satellite imagery, the devices used to capture \n",
    "the images have multiple sensors, each sensor is for a different reflective spectral \n",
    "band in the electromagnetic wavelength (Science Education through Earth Observation \n",
    "for High Schools (SEOS) and European Association of Remote Sensing Laboratories n.d.). \n",
    "A band alone cannot convey much, but the relationship between two or more bands \n",
    "does - these are normalized spectral indices such as NDMI, NDVI, and others (United \n",
    "States Geological Survey (USGS) n.d.). Information on more in detail about remote \n",
    "sensing can be found \n",
    "[here](https://seos-project.eu/remotesensing/remotesensing-c01-p06.html) (Science \n",
    "Education through Earth Observation for High Schools (SEOS) and European Association \n",
    "of Remote Sensing Laboratories n.d.). NDVI will be used in this project in order to \n",
    "calculate the vegetation statistics. These vegetation statistics will be used to be \n",
    "able to see if those variables can predict % depression prevalence in Denver.\n",
    "\n",
    "To access the NAIP data the Microsoft Planetary Computer STAC (SpatioTemporal \n",
    "AccessCatalog) API was used. The Microsoft Planetary Copmuter is comprised of \n",
    "3 main components - the data catalog (this project uses STAC), API's (of which \n",
    "this project will use in order to search for the data needed), and applications \n",
    "(Microsoft. n.d.). The NAIP data is freely accessible via the STAC and a \n",
    "an account is not needed (the data and API can be used anonymously) to access this \n",
    "data (Microsoft. n.d.). In order to interact with the Microsoft Planetary Computer \n",
    "the module 'pystac_client' needs to be imported; it's possible depending on the \n",
    "python environment being used that other imports may be necessary (Microsoft. n.d.). \n",
    "The NAIP data comes from a 'professional' source (USGS) and gathered through aerial \n",
    "imagery that is orthorectified, so there should be a degree of trust in the data, \n",
    "but it depends on how it is being used and what it is being used for (United States \n",
    "Geological Survey (USGS) - Earth Resources Observation and Science (EROS) Center, \n",
    "n.d.). \n",
    "\n",
    "The NAIP data can vary depending on the timeframe used because the data is collected \n",
    "every 3 years starting in 2003, and is only captured during the agricultural growing \n",
    "season (United States Geological Survey (USGS) - Earth Resources Observation and \n",
    "Science (EROS) Center, n.d.). That is something to keep in mind when setting up the \n",
    "temporal parameter - if 2004 was set as the 'datetime', or December 31, 2003 it \n",
    "wouldn't pull any data - for 2004, that year no imagery was captured, and while 2003 \n",
    "was captured, that day and month wouldn't be within the agricultural growing season \n",
    "(United States Geological Survey (USGS) - Earth Resources Observation and Science \n",
    "(EROS) Center, n.d.). Another element to keep in mind is cloud coverage, of which \n",
    "there will be as much as 10% cloud coverage per tile (United States Geological Survey \n",
    "(USGS) - Earth Resources Observation and Science (EROS) Center, n.d.). When working \n",
    "with imagery is best to get a 'clear' image or images where there is little to no \n",
    "cloud coverage for the best results. Luckily because this data is only captured during \n",
    "the growing season when vegetation is healthiest and would have the greatest \n",
    "percentage reflection and in theory would be less cloud coverage than non-growing \n",
    "season, means that getting a clear image should not be as much effort as getting \n",
    "one in 'Harmonized Landsat Sentinel-2' would be. \n",
    "\n",
    "The reason why NAIP was chosen as the data source, was because other sources like \n",
    "'Harmonized Landsat Sentinel-2', have lower resolution at 30m and that would not \n",
    "be able to capture the structure of the green space, like: edge density, mean \n",
    "patch size, and fragmentation (NASA 2023). The vegetation variables (edge density, \n",
    "mean patch size, and fragmentation) are actually statistics that attempt to quantify \n",
    "the connectivity and structure of green space. Edge density is the total length of \n",
    "all patch areas (perimeter) divded by the total area of the landscape (for this \n",
    "project it's the total area of the census tract) (Ene and Mcgarigal 2023, “(L4) \n",
    "Edge Density”). Mean patch size is the total area of of the patch, and taking the \n",
    "mean of patch size for all patches in the landscape (for this project that will be \n",
    "for all patches in a census tract) (Ene and Mcgarigal 2023, “Landscape Metrics”). \n",
    "Fragmentation is the number of patches or edge density in a specified area (Fahrig \n",
    "2023). The graphic below helps visualize what some of these terms mean, however it \n",
    "is about habitat so instead, think of the landscape is the census tract \n",
    "and the patch is the vegetation pixel or group of veg pixels in that census tract; \n",
    "the more patches within a census tract increases fragmentation and edge density \n",
    "(Fahrig 2023).\n",
    "\n",
    "<figure>\n",
    "    <img\n",
    "        src=\"https://conbio.onlinelibrary.wiley.com/cms/asset/ab77d47a-27ae-4e05-a1b4-54860308571c/conl12992-fig-0001-m.png\"\n",
    "        alt=\"Graphic explaining landscape metrics (Fahrig 2023)\" \n",
    "        height=\"300px\"/>    \n",
    "    <figcaption aria-hidden=\"true\">\n",
    "        Graphic explaining 'For a given total amount of habitat in a landscape \n",
    "        (sum of green areas within the large squares), the total length of habitat \n",
    "        edge (in darker green) increases with increasing habitat fragmentation.'\n",
    "        (Fahrig 2023)\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "### NAIP Citations:\n",
    "\n",
    "* Ene, Eduard, and Kevin Mcgarigal. 2023. “Landscape Metrics.” Fragstats.org. 2023. \n",
    "https://fragstats.org/index.php/background/landscape-metrics.\n",
    "\n",
    "* Ene, Eduard, and Kevin Mcgarigal. 2023. “(L4) Edge Density.” Fragstats.org. 2023. \n",
    "https://fragstats.org/index.php/fragstats-metrics/patch-based-metrics/area-and-edge-metrics/l4-edge-density.\n",
    "\n",
    "* Fahrig, Lenore. 2023. “Patch‐Scale Edge Effects Do Not Indicate Landscape‐Scale \n",
    "Fragmentation Effects.” Conservation Letters 17 (1). https://doi.org/10.1111/conl.12992.\n",
    "\n",
    "* GeoNext, and Krishnagopal Halder. 2024. “Getting Started with Microsoft \n",
    "Planetary Computer STAC API.” Medium. March 19, 2024. \n",
    "https://medium.com/@geonextgis/getting-started-with-microsoft-planetary-computer-stac-api-67cbebe96e5e.\n",
    "\n",
    "* Microsoft. n.d. “About the Microsoft Planetary Computer.” \n",
    "Planetarycomputer.microsoft.com. \n",
    "https://planetarycomputer.microsoft.com/docs/overview/about/.\n",
    "\n",
    "* NASA. 2023. “L30 – Harmonized Landsat Sentinel-2: Products Description.” \n",
    "Nasa.gov. 2023. https://hls.gsfc.nasa.gov/products-description/l30/.\n",
    "\n",
    "* Science Education through Earth Observation for High Schools (SEOS), and European \n",
    "Association of Remote Sensing Laboratories. n.d. “Introduction to Remote Sensing.” \n",
    "Seos-Project.eu. Accessed February 22, 2025. \n",
    "https://seos-project.eu/remotesensing/remotesensing-c01-p06.html.\n",
    "\n",
    "* United States Geological Survey (USGS). n.d. “Landsat Surface Reflectance-Derived \n",
    "Spectral Indices | U.S. Geological Survey.” Www.usgs.gov. USGS. Accessed February 22, 2025. \n",
    "https://www.usgs.gov/landsat-missions/landsat-surface-reflectance-derived-spectral-indices.\n",
    "\n",
    "* United States Geological Survey (USGS) - Earth Resources Observation and Science (EROS) \n",
    "Center . 2018. “USGS EROS Archive - Aerial Photography - High Resolution Orthoimagery (HRO) \n",
    "| U.S. Geological Survey.” Www.usgs.gov. July 6, 2018. https://www.usgs.gov/centers/eros/science/usgs-eros-archive-aerial-photography-high-resolution-orthoimagery-hro.\n",
    "\n",
    "* United States Geological Survey (USGS) -Earth Resources Observation and Science (EROS) \n",
    "Center. n.d. “USGS EROS Archive - Aerial Photography - National Agriculture Imagery Program \n",
    "(NAIP) | U.S. Geological Survey.” Www.usgs.gov. https://www.usgs.gov/centers/eros/science/usgs-eros-archive-aerial-photography-national-agriculture-imagery-program-naip.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods Description\n",
    "\n",
    "OLS Regression will be used as the model to find out if there is a \n",
    "statistically significant relationship between depression and greenspace.\n",
    "This will be using the variables of % of depression prevalence and \n",
    "vegeation related variables. Models can be used for different purposes \n",
    "in earth data science, one of which is prediction. Here, the goal is to see \n",
    "if the model can predict the depression prevalence accurately. In order to \n",
    "evaluate the model, calculated error could be looked at or calculate \n",
    "R squared which would say what percent of variation in depression prevalence \n",
    "can be explained by the model. However, when choosing a model it is important \n",
    "to take into account assumptions about the data and if the model is appropriate \n",
    "given the data. Some important assumptions about OLS regression are: \n",
    "linearity - assuming there is a linear relationship between the two variables, \n",
    "normally distributed error - data shouldn't have long tails, \n",
    "independence - avoid co-linearity of tightly correlated variables, \n",
    "stationarity - parameters of the model should not vary over time, \n",
    "and complete observations - shouldn't have large amounts of no data \n",
    "values.\n",
    "\n",
    "The data can be manipulated or adjusted to be a better fit. For example:\n",
    "* no data values can be dropped to account for complete observations using .dropna()\n",
    "* log of variables can be taken to make the data more normally distributed and \n",
    "not have long tails using np.log.\n",
    "* normalization/standardization of data to account for the different scales \n",
    "of the variables\n",
    "* Etc.\n",
    "\n",
    "For this project independence and stationairity are not of major concern, but \n",
    "there are no data values, the data has tails, and the two variables do have \n",
    "very different scales, so the data needs to have the fixes done to fit the model.\n",
    "There is a delicate balance of fitting versus overfitting.\n",
    "Potential issues with choosing this model are using the variables given, \n",
    "there may not be a linear relationship and so the results may be quite muddy or \n",
    "not relay that there is a relationship between the variables. Another potential \n",
    "issue is overfitting the model - this would mean making so many or enough \n",
    "adjustments to the data to 'fit it' and it results in the model fitting to \n",
    "the noise having very low error and not much can be relayed of a possible \n",
    "relationship between the variables when this happens. Because overfitting \n",
    "in particular is a worry here, a way to avoid that, is cross validation.\n",
    "\n",
    "Cross validation...\n",
    "\n",
    "Computing model error...\n",
    "\n",
    "Personally not having much experience in Earth Data Science and Statistics,\n",
    "I am unfamiliar with other possible models that could be used here. Another \n",
    "one I know of it the Decision Tree Model but would need to do more research \n",
    "if other models would be appropriate here.\n",
    "\n",
    "### Citations:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Analysis and Site Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Analysis Part 1 of 2\n",
    "\n",
    "# Import libraries to help with ...\n",
    "\n",
    "# Reproducible file paths\n",
    "import os # Reproducible file paths\n",
    "from glob import glob # Find files by pattern\n",
    "import pathlib # Find the home folder\n",
    "import time # formatting time\n",
    "import warnings # Filter warning messages\n",
    "import zipfile # Work with zip files\n",
    "from io import BytesIO # Stream binary (zip) files\n",
    "\n",
    "# Find files by pattern\n",
    "import numpy as np # adjust images \n",
    "import matplotlib.pyplot as plt # Overlay pandas and xarry plots, Overlay raster and vector data\n",
    "import requests # Request data over HTTP\n",
    "\n",
    "# Work with tabular, vector, and raster data\n",
    "import cartopy.crs as ccrs # CRSs (Coordinate Reference Systems)\n",
    "import geopandas as gpd # work with vector data\n",
    "import geoviews as gv # holoviews extension for data visualization\n",
    "import hvplot.pandas # Interactive tabular and vector data\n",
    "import hvplot.xarray # Interactive raster\n",
    "import pandas as pd # Group and aggregate\n",
    "import pystac_client # Modify returns from API\n",
    "import shapely # Perform geometric operations on spatial data\n",
    "import xarray as xr # Adjust images\n",
    "import rioxarray as rxr # Work with geospatial raster data\n",
    "from rioxarray.merge import merge_arrays # Merge rasters\n",
    "\n",
    "# Processing and regression related\n",
    "from scipy.ndimage import convolve # Image and signal processing\n",
    "from sklearn.model_selection import KFold # Cross validation\n",
    "from scipy.ndimage import label # Labels connected features in an array\n",
    "from sklearn.linear_model import LinearRegression # Work with linear regression models\n",
    "from sklearn.model_selection import train_test_split # Split data into subsets - evaluate model\n",
    "from tqdm.notebook import tqdm # Visualize progress of iterative operations\n",
    "\n",
    "# import to be able to save plots\n",
    "import holoviews as hv # be able to save hvplots\n",
    "\n",
    "# Suppress third party warnings - 'ignore'\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Prevent GDAL from quitting due to momentary disruptions\n",
    "os.environ[\"GDAL_HTTP_MAX_RETRY\"] = \"5\"\n",
    "os.environ[\"GDAL_HTTP_RETRY_DELAY\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Analysis Part 2 of 2\n",
    "\n",
    "# Set up census tract path\n",
    "# Define and create the project data directory\n",
    "den_census_tracts_data_dir = os.path.join(\n",
    "    pathlib.Path.home(),\n",
    "    'documents',\n",
    "    'earth-analytics',\n",
    "    'urban_greenspace_denver'\n",
    ")\n",
    "os.makedirs(den_census_tracts_data_dir, exist_ok=True)\n",
    "\n",
    "# Call the data dir to confirm location\n",
    "den_census_tracts_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the census tracts from CDC (only once) Part 1 of 1\n",
    "\n",
    "# Define info for census tract download\n",
    "den_census_tracts_dir = os.path.join(den_census_tracts_data_dir, 'denver-tract')\n",
    "os.makedirs(den_census_tracts_dir, exist_ok=True)\n",
    "den_census_tracts_path = os.path.join(den_census_tracts_dir, '*.shp')\n",
    "\n",
    "# Only download once (conditional statement)\n",
    "if not os.path.exists(den_census_tracts_path):\n",
    "    den_census_tracts_url = (\n",
    "    'https://data.cdc.gov/download/x7zy-2xmx/application%2Fzip'\n",
    "    )\n",
    "    den_census_tracts_gdf = gpd.read_file(den_census_tracts_url)\n",
    "    denver_tracts_gdf = den_census_tracts_gdf[den_census_tracts_gdf.PlaceName=='Denver']\n",
    "    denver_tracts_gdf.to_file(den_census_tracts_path, index=False)\n",
    "\n",
    "# Load in the census tract data\n",
    "denver_tracts_gdf = gpd.read_file(den_census_tracts_path)\n",
    "\n",
    "# Call the chicago tracts gdf to see it\n",
    "denver_tracts_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the census tracts for state of CO (only once) Part 1 of 1\n",
    "\n",
    "# Define info for census tract download\n",
    "den_tiger_tracts_dir = os.path.join(den_census_tracts_data_dir, 'colorado-tracts')\n",
    "os.makedirs(den_tiger_tracts_dir, exist_ok=True)\n",
    "den_tiger_tracts_path = os.path.join(den_tiger_tracts_dir, '*.shp')\n",
    "\n",
    "# Only download once (conditional statement)\n",
    "if not os.path.exists(den_tiger_tracts_path):\n",
    "    co_tiger_tracts_url = (\n",
    "    'https://www2.census.gov/geo/tiger/TIGER2024/TRACT/tl_2024_08_tract.zip'\n",
    "    )\n",
    "    co_tiger_tracts_gdf = gpd.read_file(co_tiger_tracts_url)\n",
    "    # COUNTYFP 031 is Denver County which in this case is also the City of Denver\n",
    "    # It's a City and a County\n",
    "    den_tiger_tracts_gdf = co_tiger_tracts_gdf[co_tiger_tracts_gdf.COUNTYFP=='031']\n",
    "    den_tiger_tracts_gdf.to_file(den_tiger_tracts_path, index=False)\n",
    "\n",
    "# Load in the census tract data\n",
    "den_tiger_tracts_gdf = gpd.read_file(den_tiger_tracts_path)\n",
    "\n",
    "# Call the chicago tracts gdf to see it\n",
    "den_tiger_tracts_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a spatial join for census tracts at least partially \n",
    "# within City of Denver boundary\n",
    "\n",
    "# this new gdf needs to be joined to the previous one from CDC which\n",
    "# is already clipped to the city boundary, so no need to download a \n",
    "# seperate city boundary shapefile which reduces the amount of things \n",
    "# being downloaded\n",
    "\n",
    "# Define new variable for the joind gdf\n",
    "joined_den_tracts_gdf = (\n",
    "    gpd.sjoin(\n",
    "        # TIGER tracts gdf - only need tracts that intersect with..\n",
    "        den_tiger_tracts_gdf.to_crs(ccrs.Mercator()),\n",
    "        # CDC tracts gdf - which are already clipped to the Chicago city boundary\n",
    "        denver_tracts_gdf.to_crs(ccrs.Mercator()), \n",
    "        # Specify type of join (\"inner\", \"left\", \"right\")\n",
    "        how=\"inner\", \n",
    "        # Specify the spatial relationship (\"intersects\", \"within\", \"contains\")\n",
    "        predicate=\"intersects\"\n",
    "        )\n",
    ")\n",
    "\n",
    "# Explore the result\n",
    "joined_den_tracts_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to see how many rows there are because I think there's duplicates\n",
    "num_rows = joined_den_tracts_gdf.shape[0]\n",
    "print(\"Number of rows:\", num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate geometries\n",
    "\n",
    "# Normalize the geometry column to ensure consistent representation\n",
    "joined_den_tracts_gdf['geometry'] = joined_den_tracts_gdf.geometry.normalize()\n",
    "\n",
    "# Drop duplicate rows based on the geometry column\n",
    "dropped_joined_den_tracts_gdf = joined_den_tracts_gdf.drop_duplicates(subset='geometry')\n",
    "\n",
    "# Call the gdf to see it\n",
    "dropped_joined_den_tracts_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site plot -- Census tracts with satellite imagery in the background\n",
    "# Create new variable for plot in order to save it later\n",
    "joined_denver_tracts_plot = dropped_joined_den_tracts_gdf.to_crs(\n",
    "# Use hvplot to plot and set parameters\n",
    "ccrs.Mercator()).hvplot(\n",
    "    geo=True, crs=ccrs.Mercator(),\n",
    "    tiles='EsriImagery',\n",
    "    title='City and County of Denver - Site Plot of Census Tracts',\n",
    "    fill_color=None, line_color='darkorange', \n",
    "    line_width=3, #frame_width=600\n",
    "    width=700 , height=500\n",
    ")\n",
    "\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(joined_denver_tracts_plot, 'joined_den_site_plot_using_tiger_and_cdc.html')  \n",
    "\n",
    "# Display the plot\n",
    "joined_denver_tracts_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Site Plot of Census Tracts for Denver: dispersed \n",
    "## tracts that also vary in size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The City and County of Denver census tracts show how the \n",
    "northeast has much larger area of tracts than the rest of the \n",
    "city. The largest one is the airport in the largest tract in the \n",
    "northeast corner. It may be worth considering taking out the airport \n",
    "census tract if there isn't housing, but more research will need to be \n",
    "done on that. However, the airport with emissions may contribute to asthma \n",
    "prevalance as well, but that's not the point or goal of this project. Due \n",
    "to the airport tract the city ranges roughly 1 degree latitude and \n",
    "longitude. Visually the greenspace in the city appears mostly in the \n",
    "'inverted L' as well as in the southwest corner where there is a small \n",
    "lake (Marston Lake). As mentioned in the site description the 'inverted L' \n",
    "tracing roughly I-25 going north to south and I-70 going west to east. \n",
    "Those highways are highly visible even in with the census tracts \n",
    "overlay - the highways look grey with highly developed areas around them. \n",
    "The 'inverted L' will continue to play a role in analysis of plots and data. \n",
    "\n",
    "Location of greenspace is also tied to the effects of redlining as mentioned \n",
    "in the site description. So there may be possible connections between socio-economic \n",
    "data, asthma prevalence, and urban greenspace. Which leaves room for further \n",
    "study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depression Data Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links to asthma data - for reference (both original and archived)\n",
    "\n",
    " \"https://archive.org/download/20250128-cdc-datasets/PLACES_Local_Data_for_Better_Health_Census_Tract_Data_2022_release.csv\"\n",
    "\n",
    " \"https://data.cdc.gov/api/views/cwsq-ngmh/rows.csv?accessType=DOWNLOAD\"\n",
    "\n",
    " \"https://data.cdc.gov/resource/cwsq-ngmh.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a path for the asthma data\n",
    "den_cdc_depression_path = os.path.join(den_census_tracts_data_dir, 'asthma.csv')\n",
    "\n",
    "# Download asthma data (only once)\n",
    "if not os.path.exists(den_cdc_depression_path):\n",
    "    # Define new variable for url\n",
    "    cdc_places_tracts_url = (\n",
    "        \n",
    "        \"https://archive.org/download/20250128-cdc-datasets/PLACES_Local_Data_for_Better_Health_Census_Tract_Data_2022_release.csv\"\n",
    "        #\"&StateAbbr=CO\"\n",
    "        #\"&CountyName=Denver\"\n",
    "        #\"&Measureid=CASTHMA\"\n",
    "        #\"&$limit=1500\"\n",
    "    )\n",
    "\n",
    "    # Make a request to the URL and show progress with tqdm\n",
    "    print(\"Downloading data...\")\n",
    "    response = requests.get(cdc_places_tracts_url, stream=True)\n",
    "\n",
    "    # Check for successful request (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Total size of the response in bytes for tqdm\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        # Download and save the file in chunks, updating the progress bar\n",
    "        with open(den_cdc_depression_path, 'wb') as f, tqdm(\n",
    "            total=total_size, unit='B', unit_scale=True, desc=\"Downloading depression data\"\n",
    "        ) as pbar:\n",
    "            for data in response.iter_content(chunk_size=1024):\n",
    "                f.write(data)\n",
    "                pbar.update(len(data))  # Update the progress bar with the chunk size\n",
    "    else:\n",
    "        print(f\"Failed to download data. HTTP Status code: {response.status_code}\")\n",
    "    \n",
    "    # After download, process the CSV and load into a DataFrame\n",
    "    print(\"Processing the downloaded data...\")\n",
    "\n",
    "    # Define new variable for dataframe\n",
    "    cdc_df = (\n",
    "        # Read a CSV file into a dataframe\n",
    "        pd.read_csv(den_cdc_depression_path)\n",
    "        # Replace column names as needed - 'old_name':'new_name'\n",
    "        .rename(columns={\n",
    "            'Data_Value': 'depression',\n",
    "            'Low_Confidence_Limit': 'depression_ci_low',\n",
    "            'High_Confidence_Limit': 'depression_ci_high',\n",
    "            'LocationName': 'tract'})\n",
    "        # Select specifc columns needed/wanted with double brackets    \n",
    "        [[\n",
    "            'MeasureId',\n",
    "            'CountyName',\n",
    "            'Year', \n",
    "            'tract', \n",
    "            'depression', 'depression_ci_low', 'depression_ci_high', 'Data_Value_Unit',\n",
    "            'TotalPopulation'\n",
    "        ]]\n",
    "    )\n",
    "\n",
    "    # Filter based on multiple conditions:\n",
    "    den_cdc_depression_df = cdc_df[\n",
    "        # Select the health outcome wanted from the measure id\n",
    "        (cdc_df['MeasureId'] =='DEPRESSION') & \n",
    "        # Select the county name\n",
    "        (cdc_df['CountyName'] =='Denver')\n",
    "        # If the county name occurs in more than one state,\n",
    "        # the sateabbr would need to be chosen and included in this \n",
    "        # selection and in the columns wanted above\n",
    "    ]\n",
    "\n",
    "    # Save dataframe to a CSV (tabular data) file\n",
    "    den_cdc_depression_df.to_csv(\n",
    "        den_cdc_depression_path, \n",
    "        # Prevent a new index column from being created\n",
    "        index=False\n",
    "        )\n",
    "\n",
    "# Load in asthma data\n",
    "den_cdc_depression_df = pd.read_csv(den_cdc_depression_path)\n",
    "\n",
    "# Preview asthma data\n",
    "den_cdc_depression_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change tract identifier datatype for merging\n",
    "dropped_joined_den_tracts_gdf.tract2010 = dropped_joined_den_tracts_gdf.tract2010.astype('int64')\n",
    "\n",
    "# Merge census data with geometry\n",
    "den_tract_cdc_gdf = (\n",
    "    # Census tracts gdf\n",
    "    dropped_joined_den_tracts_gdf\n",
    "    # Use the .merge() method\n",
    "    .merge(\n",
    "        # Depression prevalence dataframe\n",
    "        den_cdc_depression_df, \n",
    "        # Specify the column/index to merge on for Census tracts gdf\n",
    "        left_on='tract2010', \n",
    "        # Specify the column/index to merge on for the depression dataframe\n",
    "        right_on='tract', \n",
    "        # Specify type of join (\"inner\", \"left\", \"right\")\n",
    "        how='inner'\n",
    "        )\n",
    ")\n",
    "\n",
    "# Plot depression data as chloropleth\n",
    "den_chloropleth_depression_by_tract = (\n",
    "# Use EsriImagery tiles for the background\n",
    "(   gv.tile_sources.EsriImagery\n",
    "    * \n",
    "    gv.Polygons(\n",
    "        # Change gdf CRS to mercator\n",
    "        den_tract_cdc_gdf.to_crs(ccrs.Mercator()),\n",
    "        # Set variables for the plot\n",
    "        vdims=['depression', 'tract2010'],\n",
    "        # Set CRS to Mercator\n",
    "        crs=ccrs.Mercator()\n",
    "    ).opts(\n",
    "        # Add a colorbar and label\n",
    "        color='depression', colorbar=True, \n",
    "        clabel='% of Depression Prevalence in Popultation',\n",
    "        tools=['hover'])\n",
    ").opts(\n",
    "    # Plot size, title, and axes labels\n",
    "    title= 'Denver - Depression Prevalence by Census Tract',\n",
    "    # Set the width and the height\n",
    "    width=800, height=500,\n",
    "    # Drop the axes labels\n",
    "    xaxis=None, yaxis=None,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(den_chloropleth_depression_by_tract, 'den_chloropleth_depression_by_tract.html')  \n",
    "\n",
    "# Display the plot\n",
    "den_chloropleth_depression_by_tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the denver cdc gdf to see it\n",
    "den_tract_cdc_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depression Prevalence Plot Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, it appears that the west side is slightly darker \n",
    "shades of blue than the west half of the city - so higher % prevalence of\n",
    "depression, with one census tract in particular that appears to be an \n",
    "outlier tract in the northwest. This one census tract has the highest \n",
    "% prevalence of depression which is interesting and will be kept in mind \n",
    "for future analysis. The lighter shades of blue, lower % prevalence of \n",
    "depression are located mostly in the central east and central south east, with \n",
    "a few larger size census tracts in the central north that are also lower % \n",
    "prevalence. \n",
    "\n",
    "This somewhat line up with the idea of the 'inverted L' () having the lower % \n",
    "prevalence of depression in the central west and southwest, but that's not 100% \n",
    "true given some of the tracts beyond the 'inverted L' () do have lower % prevalence \n",
    "rates as well. There are clear connections in the research made between greenspace \n",
    "and depression \n",
    "# (), \n",
    "so it will be interesting to see if there is a relationship between \n",
    "urban greenspace and % depression prevalence in further analyses. Additionally, \n",
    "the 'inverted L' will continue to be looked at or kept in mind in further analyses\n",
    "# ().\n",
    "\n",
    "Population size will also need to be kept in mind because while a cenus tract might \n",
    "have a higher % of depression prevalence, there might be signifcantly fewer total \n",
    "population - which would skew the data. So, I might try to plot on population size or \n",
    "density because I think that is worth considering in the % of depression prevalence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAIP Wrangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the planetary computer catalog\n",
    "e84_catalog = pystac_client.Client.open(\n",
    "    \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    ")\n",
    "e84_catalog.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert geometry to lat/lon for STAC\n",
    "den_tract_latlon_gdf = den_tract_cdc_gdf.to_crs(4326)\n",
    "\n",
    "# Define a path to save NDVI stats\n",
    "den_ndvi_stats_path = os.path.join(den_census_tracts_data_dir, 'denver-ndvi-stats.csv')\n",
    "\n",
    "# Check for existing data - do not access duplicate tracts\n",
    "\n",
    "# Create a list to accumulate downloaded tracts\n",
    "den_downloaded_tracts = []\n",
    "# If Else statement to control specifc blocks of code\n",
    "# Code to execute if the condition is true\n",
    "if os.path.exists(den_ndvi_stats_path):\n",
    "    den_ndvi_stats_df = pd.read_csv(den_ndvi_stats_path)\n",
    "    den_downloaded_tracts = den_ndvi_stats_df.tract.values\n",
    "# Code to execute if the condition is false\n",
    "else:\n",
    "    print('No census tracts downloaded so far')\n",
    "\n",
    "\n",
    "# Loop through each census tract\n",
    "\n",
    "# Create list of dataframes, list needs to be outside of loop\n",
    "den_scene_dfs = []\n",
    "# Start for loop\n",
    "for i, den_tract_values in tqdm(den_tract_latlon_gdf.iterrows(), ncols=100):\n",
    "    den_tract = den_tract_values.tract\n",
    "    # Check if statistics are already downloaded for this tract\n",
    "    if not (den_tract in den_downloaded_tracts):\n",
    "        # Retry up to 5 times in case of a momentary disruption\n",
    "        i = 0\n",
    "        retry_limit = 5\n",
    "        # Loop for executing code block as long as specified condition is true\n",
    "        while i < retry_limit:\n",
    "            # Try accessing the STAC\n",
    "            try:\n",
    "                # Search for tiles\n",
    "                naip_search = e84_catalog.search(\n",
    "                    # In the NAIP collection\n",
    "                    collections=[\"naip\"],\n",
    "                    # That intersect with geometry of census tracts\n",
    "                    intersects=shapely.to_geojson(den_tract_values.geometry),\n",
    "                    # In the year 2021\n",
    "                    datetime=\"2021\"\n",
    "                )\n",
    "                \n",
    "                # Build dataframe with tracts and tile urls\n",
    "                den_scene_dfs.append(pd.DataFrame(dict(\n",
    "                    tract=den_tract,\n",
    "                    # Convert datetime value to a pandas Timestamp, then extract just the date \n",
    "                    date=[pd.to_datetime(scene.datetime).date() \n",
    "                          # of the items in the NAIP search\n",
    "                          for scene in naip_search.items()],\n",
    "                    # Reference image from the assets folder of the items in the NAIP search?   \n",
    "                    rgbir_href=[scene.assets['image'].href for scene in naip_search.items()],\n",
    "                )))\n",
    "                # Add break to prevent long waits during debugging\n",
    "                break\n",
    "            # Try again in case of an APIError\n",
    "            except pystac_client.exceptions.APIError:\n",
    "                print(\n",
    "                    f'Could not connect with STAC server. '\n",
    "                    f'Retrying tract {den_tract}...')\n",
    "                time.sleep(2)\n",
    "                i += 1\n",
    "                # Skip the rest of the current iteration and move on to the next one\n",
    "                continue\n",
    "    \n",
    "# Concatenate the url dataframes\n",
    "# Code to execute if the condition is true\n",
    "if den_scene_dfs:\n",
    "    den_scene_df = pd.concat(den_scene_dfs).reset_index(drop=True)\n",
    "# Code to execute if the condition is false\n",
    "else:\n",
    "    den_scene_df = None\n",
    "\n",
    "# Preview the URL DataFrame\n",
    "den_scene_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See dropped_joined_den_tracts because the merge \n",
    "# below didn't work because of an index error\n",
    "dropped_joined_den_tracts_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped_joined_den_tracts_gdf has a '0' in front of all \n",
    "# the values for tract2010 (because the stateFP is 08). But...\n",
    "# the NAIP automatically dropped the '0' in front of all the \n",
    "# values for the 'tract' column. \n",
    "\n",
    "# Create a copy of dropped_joined_den_tracts_gdf to perserve the original\n",
    "stripped_den_census_tracts_gdf = dropped_joined_den_tracts_gdf.copy()\n",
    "\n",
    "# Remove/strip the leading '0' from the values of the 'tract2010'\n",
    "# column of the gdf in order to index correctly\n",
    "stripped_den_census_tracts_gdf['tract2010'\n",
    "    ] = stripped_den_census_tracts_gdf['tract2010'].str.lstrip('0')\n",
    "\n",
    "# Call the gdf to make sure that worked\n",
    "stripped_den_census_tracts_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute NDVI Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this step if data are already downloaded \n",
    "if not den_scene_df is None:\n",
    "    all_den_ndvi_dfs = []\n",
    "    # Loop through the census tracts with URLs\n",
    "    for tract, tract_date_gdf in tqdm(den_scene_df.groupby('tract')):\n",
    "        # Open all images for tract\n",
    "        all_den_tile_das = []\n",
    "        # Create for loop, iterate over rows\n",
    "        for _, href_s in tract_date_gdf.iterrows():\n",
    "            # Open vsi connection to data\n",
    "            all_den_tile_da = rxr.open_rasterio(\n",
    "                # File path/url to the multispectral image\n",
    "                href_s.rgbir_href, \n",
    "                # Create masked array, then remove any single-dimensional axes from it\n",
    "                masked=True).squeeze()\n",
    "            \n",
    "            # Crop data to the bounding box of the census tract\n",
    "            # Create the boundary\n",
    "            all_den_boundary = (\n",
    "                # Using the census tract gdf\n",
    "                den_tract_cdc_gdf\n",
    "                # Set the 'tract2010' as the index of the gdf\n",
    "                .set_index('tract2010')\n",
    "                # Select the tracts from the gdf\n",
    "                .loc[[tract]]\n",
    "                # Set to the same CRS as the images for the tracts\n",
    "                .to_crs(all_den_tile_da.rio.crs)\n",
    "                # Access the geometry of the tracts to perform further operations\n",
    "                .geometry\n",
    "            )\n",
    "            # Crop the data to bounding box\n",
    "            all_den_crop_da = all_den_tile_da.rio.clip_box(\n",
    "                # Compute bounding box (min and max coordinates) of census tract geometry\n",
    "                *all_den_boundary.envelope.total_bounds,\n",
    "                # Expand bounding box slightly beyond its original extent to ensure full coverage\n",
    "                auto_expand=True)\n",
    "            \n",
    "            # Clip data to the boundary of the census tract\n",
    "            all_den_clip_da = all_den_crop_da.rio.clip(all_den_boundary, all_touched=True)\n",
    "\n",
    "            # Compute NDVI ((NIR - Red)/(NIR + Red))\n",
    "            all_den_ndvi_da = (\n",
    "                (all_den_clip_da.sel(band=4) - all_den_clip_da.sel(band=1)) \n",
    "                / (all_den_clip_da.sel(band=4) + all_den_clip_da.sel(band=1))\n",
    "            )\n",
    "            \n",
    "            # Accumulate result\n",
    "            all_den_tile_das.append(all_den_ndvi_da)\n",
    "\n",
    "        # Merge data\n",
    "        all_den_scene_da = merge_arrays(all_den_tile_das)\n",
    "\n",
    "        # Mask vegetation\n",
    "        all_den_veg_mask = (all_den_scene_da>.3)\n",
    "\n",
    "        # Calculate statistics and save data to file\n",
    "        # Calculate total number of non-missing (valid) pixels in the merged raster\n",
    "        total_pixels = all_den_scene_da.notnull().sum()\n",
    "        # Calculates total number of pixels that are classified as vegetation\n",
    "        veg_pixels = all_den_veg_mask.sum()\n",
    "\n",
    "        # Calculate mean patch size\n",
    "        # Label the connected areas\n",
    "        all_labeled_patches, all_num_patches = label(all_den_veg_mask)\n",
    "        # Count patch pixels, ignoring background at patch 0\n",
    "        all_patch_sizes = np.bincount(all_labeled_patches.ravel())[1:] \n",
    "        # Get the mean \n",
    "        all_mean_patch_size = all_patch_sizes.mean()\n",
    "\n",
    "        # Calculate edge density\n",
    "        all_kernel = np.array([\n",
    "            [1, 1, 1], \n",
    "            [1, -8, 1], \n",
    "            [1, 1, 1]])\n",
    "        \n",
    "        # Apply convolution to the vegetation mask\n",
    "        all_den_edges = convolve(\n",
    "            # Input array - the array to apply convolution on\n",
    "            all_den_veg_mask, \n",
    "            # Kernel array - the smaller array that defines the filter to be applied\n",
    "            all_kernel, \n",
    "            # Input array is extended beyond its boundaries by - \n",
    "            # filling all values beyond the edge with the same constant value\n",
    "            mode='constant')\n",
    "\n",
    "        # Calculate edge density = \n",
    "        # count of edge pixels present / total number of pixels in the veg_mask\n",
    "        all_den_edge_density = np.sum(all_den_edges != 0) / all_den_veg_mask.size\n",
    "\n",
    "        # Add a row to the statistics file for this tract\n",
    "        pd.DataFrame(dict(\n",
    "            # Unique identifier for a given tract\n",
    "            tract=[tract],\n",
    "            # Cast total number of pixels to an integer\n",
    "            total_pixels=[int(total_pixels)],\n",
    "            # Cast the fraction of pixels in the tract that are vegetation to a float\n",
    "            frac_veg=[float(veg_pixels/total_pixels)],\n",
    "            # Mean patch size of vegetation for this tract,\n",
    "            all_mean_patch_size=[all_mean_patch_size],\n",
    "            # Edge density of vegetation for this tract\n",
    "            all_den_edge_density=[all_den_edge_density]\n",
    "            # Write the df to a csv file\n",
    "        )).to_csv(\n",
    "            # The file path where the CSV will be saved to\n",
    "            den_ndvi_stats_path, \n",
    "            # Ensure that the data is appended to the file rather than overwriting it\n",
    "            mode='a', \n",
    "            # Prevent the index from being written to the CSV file\n",
    "            index=False, \n",
    "            # Check if the file exists\n",
    "            header=(not os.path.exists(den_ndvi_stats_path))\n",
    "        )\n",
    "\n",
    "# Re-load results from file\n",
    "all_den_ndvi_stats_df = pd.read_csv(den_ndvi_stats_path)\n",
    "# Call this df to see it\n",
    "all_den_ndvi_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge census data with geometry\n",
    "den_ndvi_cdc_gdf = (\n",
    "    # Choose gdf that contacins geometry for Census tracts\n",
    "    den_tract_cdc_gdf\n",
    "    # Combine two df's/gdf's based on specified columns\n",
    "    .merge(\n",
    "        # Choose all_ndvi_stats_df - it contains the veg stats for each census tract\n",
    "        all_den_ndvi_stats_df,\n",
    "        # Specify tract2010 column from the tract_cdc_gdf as key for merging\n",
    "        left_on='tract', \n",
    "        # Specify the tract column from the all_ndvi_stats_df as the key for merging\n",
    "        right_on='tract', \n",
    "        # Keep only the rows where there is a matching key in both df/gdf\n",
    "        how='inner')\n",
    ")\n",
    "\n",
    "# Plot chloropleths with vegetation statistics\n",
    "def plot_chloropleth(gdf, **opts):\n",
    "    \"\"\"Generate a chloropleth with the given color column\"\"\"\n",
    "    # Plot polygons based on geometry in gdf\n",
    "    return gv.Polygons(\n",
    "        # Convert CRS of gdf to Mercator \n",
    "        gdf.to_crs(ccrs.Mercator()),\n",
    "        # Define the CRS to use for the map - Mercator\n",
    "        crs=ccrs.Mercator()\n",
    "        # Customize the plot\n",
    "    ).opts(\n",
    "        # Remove the x and y axes from the plot\n",
    "        xaxis=None, yaxis=None, \n",
    "        # Add a colorbar\n",
    "        colorbar=True, \n",
    "        # Any additional options passed when the \n",
    "        # function is called are included\n",
    "        **opts)\n",
    "\n",
    "# Create new variable for plots in order to save them later\n",
    "den_side_by_side_chlorpleths = (\n",
    "(\n",
    "    # First chloropleth for Asthma Prevalence\n",
    "    plot_chloropleth(\n",
    "        # Using the NDVI CDC gdf\n",
    "        den_ndvi_cdc_gdf,\n",
    "        # Specify that the census tracts should be colored based on the asthma column\n",
    "        color='depression', \n",
    "        # Set label for colorbar\n",
    "        clabel='% of Depression Prevalence in Population',\n",
    "        # Specify the color map to use for coloring the tracts\n",
    "        cmap='viridis',\n",
    "        # Add a title\n",
    "        title= 'Denver Census Tracts - Depression Prevalence',\n",
    "        #Set width and height\n",
    "        width=600, height=450\n",
    "        )\n",
    "    # Overlay the two plots\n",
    "    + \n",
    "    # Second chloropleth for Edge Density\n",
    "    plot_chloropleth(\n",
    "        # Using the NDVI CDC gdf\n",
    "        den_ndvi_cdc_gdf, \n",
    "        # Specify that the census tracts should be colored based on the edge_density column\n",
    "        color='all_den_edge_density', \n",
    "        # Set label for colorbar\n",
    "        clabel='Edge Density',\n",
    "        # Specify the color map to use for coloring the tracts\n",
    "        cmap='Greens',\n",
    "        # Add a title\n",
    "        title= 'Denver Census Tracts - Edge Density ',\n",
    "        # Set width and height\n",
    "        width=600, height=450\n",
    "        )\n",
    ")\n",
    ")\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(den_side_by_side_chlorpleths, 'den_side_by_side_chlorpleths.html') \n",
    "\n",
    "# Display the plots \n",
    "den_side_by_side_chlorpleths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the new gdf to see the table\n",
    "den_ndvi_cdc_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side by Side Plot Description: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some similarities in the plots above - most of the tracts \n",
    "with the highest mean NDVI are within the 'inverted L', roughly that \n",
    "is also where the lowest % of depression prevalence is, with some exceptions. \n",
    "For the Mean NDVI plot, the slightly east center going north to south has low \n",
    "mean NDVI tracts - this is also where I-25 is roughly/ the long part of the \n",
    "'inverted L'. Some of the lowest % of depression prevalence and highest mean \n",
    "NDVI is in the center but slightly east. The outlier tract that was previously \n",
    "mentioned in the Depression Prevalence Plot earlier in the northwest, is still \n",
    "seen here and is actually 2 tracts next to each other, not one. Looking at the \n",
    "same tracts on the Mean NDVI plot those tracts do have lower mean NDVI, but not \n",
    "the lowest.\n",
    "\n",
    "The areas with the higher mean NDVI do line up with the redlining map from the site \n",
    "description \n",
    "# (). \n",
    "The 'inverted L' was very clearly seen in that redlining map and is still present \n",
    "in the Mean NDVI plot above.\n",
    "\n",
    "Also, something that was not mentioned previously, but is more noticeable in these \n",
    "side by side plots, are a few areas and tracts that are completly white that are not \n",
    "the City and County of Denver, but are entirely enclosed by it, and belong to other \n",
    "counties (Hernandez, 2018). An example of this is City of Glendale in the southwest \n",
    "corner which belongs to Arapahoe County (Hernandez, 2018). The data of these areas \n",
    "were not picked up, but wanted to note what those areas were as this is not typical in \n",
    "every county in the US.\n",
    "\n",
    "The side by side plots visually indicate there may be a relationship between the \n",
    "% of depression prevalence and mean NDVI, but doing further analyses beyond visually,\n",
    "would be beneficial. While cross validation will be used next to evaluate the OLS \n",
    "model that will be made, another option would be zonal statistics. Either way the \n",
    "model needs to be evaluated to see if there is a relationship between the two \n",
    "variables that can be predicted (somewhat) accurately. \n",
    "\n",
    "### Citations:\n",
    "\n",
    "* \n",
    "\n",
    "* Hernandez, Esteban L., December 16, 2018, 'If you think Denver’s weirdly shaped,\n",
    "wait’ll you see the islands of not-Denver in Denver'. Denverite.\n",
    "https://denverite.com/2018/12/16/if-you-think-denvers-weirdly-shaped-waitll-you-see-the-islands-of-not-denver-in-denver/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable selection and transformation\n",
    "# Create new variable for the model df\n",
    "den_model_df = (\n",
    "    # Using the den_ndvi_cdc_gdf\n",
    "    den_ndvi_cdc_gdf\n",
    "    # Create a copy to avoid modifying the original data\n",
    "    .copy()\n",
    "    # Select the subet of columns needed\n",
    "    [['frac_veg', 'depression', 'all_mean_patch_size', 'all_den_edge_density', 'geometry']]\n",
    "    # Remove any rows with NaN VALUES\n",
    "    .dropna()\n",
    ")\n",
    "# Log transformation of depression data in the df\n",
    "# This is to help handle skewed data or effort to normalize it\n",
    "den_model_df['log_depression'] = np.log(den_model_df.depression)\n",
    "\n",
    "# Plot scatter matrix to identify variables that need transformation\n",
    "# Create new variable to save plots to\n",
    "den_scatter_matrix = (\n",
    "\n",
    "# Generate a scatter matrix (or pair plot)\n",
    "hvplot.scatter_matrix(\n",
    "    # Using model df\n",
    "    den_model_df\n",
    "    # Select columns to be plotted in the matrix\n",
    "    [[ \n",
    "        'all_mean_patch_size',\n",
    "        'all_den_edge_density',\n",
    "        'log_depression',\n",
    "    ]], width = 800, height = 800\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(den_scatter_matrix, 'den_scatter_matrix.html')  \n",
    "\n",
    "# Display the plots\n",
    "den_scatter_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select predictor and outcome variables\n",
    "# Define the predictor or indpendent variables\n",
    "X = den_model_df[['all_den_edge_density', 'all_mean_patch_size']]\n",
    "# Define the outcome variable or dependent variable\n",
    "y = den_model_df[['log_depression']]\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    # Specifiy that 33% of the data will be used for testing\n",
    "    X, y, test_size=0.33, \n",
    "    # Ensure that data is split randomly - the random split is reproducible\n",
    "    random_state=42)\n",
    "\n",
    "# Fit a linear regression\n",
    "#Create an instance of the linear regression model\n",
    "reg = LinearRegression()\n",
    "# Fit the training data to the linear regression model\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict depression values for the test dataset\n",
    "y_test['pred_depression'] = np.exp(\n",
    "    # Apply exponential function to predicted values to transform to original scale\n",
    "    reg.predict(X_test))\n",
    "# Apply exponential function to predicted values to transform to original scale\n",
    "y_test['depression'] = np.exp(y_test.log_depression)\n",
    "\n",
    "# Plot measured vs. predicted depression prevalence with a 1-to-1 line\n",
    "\n",
    "# Find max value of depression prevalence in the test dat to set the limits for the plot axes\n",
    "y_max = y_test.depression.max()\n",
    "\n",
    "# Create new variable to save plot to\n",
    "den_measured_v_predicted_depression = (\n",
    "(\n",
    "# Create scatterplot \n",
    " y_test.hvplot.scatter(\n",
    "        # X axis is actual depression prevalence and Y axis is predicted depression prevalence\n",
    "        x='depression', y='pred_depression',\n",
    "        # Label x axis\n",
    "        xlabel='Measured Depression Prevalence', \n",
    "        # Label y axis\n",
    "        ylabel='Predicted Depression Prevalence',\n",
    "        # Create title for plot\n",
    "        title='Linear Regression Performance - Testing Data'\n",
    "    ) \n",
    "    .opts(\n",
    "        # Scale both axes the same\n",
    "        aspect='equal', \n",
    "        # Set limits for the axes - scale according to range of actual depression values\n",
    "        xlim=(0, y_max), ylim=(0, y_max), \n",
    "        # Set size of the plot\n",
    "        height=500, width=500)\n",
    "    # Add a slope line and set color of line\n",
    ") * hv.Slope(slope=1, y_intercept=0).opts(color='black')\n",
    ")\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(den_measured_v_predicted_depression, 'den_measured_v_predicted_depression.html') \n",
    "\n",
    "# Display the plot \n",
    "den_measured_v_predicted_depression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model error for all census tracts\n",
    "# Apply exponential function to predicted values to transform to original scale\n",
    "den_model_df['pred_depression'] = np.exp(reg.predict(X))\n",
    "# Calculate model error for each Census tract, store computed errors in a new column\n",
    "den_model_df['err_depression'] = den_model_df['pred_depression'] - den_model_df['depression']\n",
    "\n",
    "# Plot chloropleths with vegetation statistics\n",
    "def plot_chloropleth(gdf, **opts):\n",
    "    \"\"\"Generate a chloropleth with the given color column\"\"\"\n",
    "    # Plot polygons based on geometry in gdf\n",
    "    return gv.Polygons(\n",
    "        # Convert CRS of gdf to Mercator \n",
    "        gdf.to_crs(ccrs.Mercator()),\n",
    "        # Define the CRS to use for the map - Mercator\n",
    "        crs=ccrs.Mercator()\n",
    "        # Customize the plot\n",
    "    ).opts(\n",
    "        # Remove the x and y axes from the plot\n",
    "        xaxis=None, yaxis=None, \n",
    "        # Add a colorbar\n",
    "        colorbar=True, \n",
    "        # Any additional options passed when the \n",
    "        # function is called are included\n",
    "        **opts)\n",
    "\n",
    "# Create new variable to save the plot to\n",
    "den_model_error_chloropleth = (\n",
    "# Plot error geographically as a chloropleth\n",
    "\n",
    "    (\n",
    "        # Color the chloropleth based on the model error\n",
    "        plot_chloropleth(den_model_df, color='err_depression', cmap='RdBu')\n",
    "        # Adjust the color scale/range for the model error\n",
    "        .redim.range(err_depression=(-.3, .3))\n",
    "        # Customize plot\n",
    "        .opts(\n",
    "            # Add a title\n",
    "            title= 'City of Denver - Model Errors for Predicted Depression Prevalence',\n",
    "            # Add a label for color bar\n",
    "            clabel= 'Model Error', \n",
    "            # Ensure aspect ratio equal (helps preserve the true shaps of census tracts)\n",
    "            aspect='equal',\n",
    "            # Set width and height\n",
    "            width = 700, height = 400\n",
    "            )\n",
    "    )\n",
    ")\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(den_model_error_chloropleth, 'den_model_error_chloropleth.html')  \n",
    "\n",
    "# Display the plot\n",
    "den_model_error_chloropleth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe and Interpret Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatter matrix doesn't show normal distribution which is something to \n",
    "keep in mind looking at the other plots made. \n",
    "\n",
    "The linear regression on the test data, visually does not show a relationship \n",
    "between predicted and actual depression prevalence - there are many data points which \n",
    "are not very close to the regression line. This relays the model didn't \n",
    "very often accurately predict depression prevalence based on vegetation related \n",
    "variables.\n",
    "\n",
    "For the chloropleth model errors, errors close to 0 are more accurate \n",
    "and the further away from 0 the less accurate. Most of the census tracts \n",
    "are either < -0.2 or > 0.2, not many are close to 0. The tracts that that are \n",
    "close to 0 for model error are somethwat centralized geographically, but there \n",
    "doesn't appear to be visually noticeable groupings. The 'inverted L' is also not \n",
    "seen here; if depression were acurately predicted based on vegetation related \n",
    "variables, I would have expected to see the 'inverted L' with low model error \n",
    "in the central and southeast, but that was not the case here. The very few tracts having \n",
    "a model error close to 0 relays is that the models predictions were not very \n",
    "accurate. Visually, the areas that need further attention are clear. \n",
    "The model error areas with -0.2 have a cluster of tracts in the southwest but that \n",
    "area also had a mixed range of mean NDVI values. So, the research related to \n",
    "greenspace and how it is thought to help depression doesn't exactly line up with \n",
    "what is being seen here.\n",
    "\n",
    "That being said, just because there may or may not be more greenspace or high mean \n",
    "NDVI, doesn't mean that someone with diagnosed depression will actually use it or \n",
    "be able to see it/ intereact with it(could live in a basement, have a view of an \n",
    "alley, etc.). Depression can be genetic or situational and greenspace may have \n",
    "nothing to do with cause for depression or depression diagnosis. It is within reason, \n",
    "that vegetation related variables and % of depression prevalence do not have a linear \n",
    "relationship, as evidenced by the scatter matrix - not normally distributed.\n",
    "\n",
    "Moving forward I think other model types could be applied if their assumptions \n",
    "are also met such as the decision tree model or random forest model, but those \n",
    "are the only other models I know of. So, there may be a model out there that is \n",
    "a better fit. It is likely that the variables chosen just don't have a linear \n",
    "relationship so OLS regression shouldn't be chosen if that's the case. \n",
    "\n",
    "Besides choosing another model, further data transformations could be done such \n",
    "as normalizing or standardizing the data to account for the very different scales \n",
    "of the depression prevalence compared to the vegetation related data (it's possible \n",
    "this was in fact done and I just didn't know that's what the code was doing). \n",
    "There's also other methods to fit data to have a normal distribution, I don't \n",
    "know much about them, but other methods for that could be researched to see if \n",
    "some other method is a better fit given the data. \n",
    "\n",
    "Additionaly data wise, a different variable could be chosen for the \n",
    "relationship to depression or vice versa. I would be interested in looking into \n",
    "a variable related to sunny days or something similar because Denver, and a lot \n",
    "of Colorado has many sunny days, which also I think might have a connection to % of \n",
    "depression prevalence. I wonder what a sun related relationship would look like or \n",
    "mean NDVI and an amount of sun or sunny days related variable relationship to depression \n",
    "prevalence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
