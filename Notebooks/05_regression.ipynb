{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from the previous notebook\n",
    "%store -r den_ndvi_cdc_gdf den_tract_cdc_gdf all_den_ndvi_stats_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to help with ...\n",
    "\n",
    "# Reproducible file paths\n",
    "import os # Reproducible file paths\n",
    "from glob import glob # Find files by pattern\n",
    "import pathlib # Find the home folder\n",
    "import time # formatting time\n",
    "import warnings # Filter warning messages\n",
    "import zipfile # Work with zip files\n",
    "from io import BytesIO # Stream binary (zip) files\n",
    "\n",
    "# Find files by pattern\n",
    "import numpy as np # adjust images \n",
    "import matplotlib.pyplot as plt # Overlay pandas and xarry plots, Overlay raster and vector data\n",
    "import requests # Request data over HTTP\n",
    "\n",
    "# Work with tabular, vector, and raster data\n",
    "import cartopy.crs as ccrs # CRSs (Coordinate Reference Systems)\n",
    "import geopandas as gpd # work with vector data\n",
    "import geoviews as gv # holoviews extension for data visualization\n",
    "import hvplot.pandas # Interactive tabular and vector data\n",
    "import hvplot.xarray # Interactive raster\n",
    "import pandas as pd # Group and aggregate\n",
    "import pystac_client # Modify returns from API\n",
    "import shapely # Perform geometric operations on spatial data\n",
    "import xarray as xr # Adjust images\n",
    "import rioxarray as rxr # Work with geospatial raster data\n",
    "from rioxarray.merge import merge_arrays # Merge rasters\n",
    "\n",
    "# Processing and regression related\n",
    "from scipy.ndimage import convolve # Image and signal processing\n",
    "from sklearn.model_selection import KFold # Cross validation\n",
    "from scipy.ndimage import label # Labels connected features in an array\n",
    "from sklearn.linear_model import LinearRegression # Work with linear regression models\n",
    "from sklearn.model_selection import train_test_split # Split data into subsets - evaluate model\n",
    "from tqdm.notebook import tqdm # Visualize progress of iterative operations\n",
    "\n",
    "# import to be able to save plots\n",
    "import holoviews as hv # be able to save hvplots\n",
    "\n",
    "# Suppress third party warnings - 'ignore'\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Prevent GDAL from quitting due to momentary disruptions\n",
    "os.environ[\"GDAL_HTTP_MAX_RETRY\"] = \"5\"\n",
    "os.environ[\"GDAL_HTTP_RETRY_DELAY\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable selection and transformation\n",
    "# Create new variable for the model df\n",
    "den_model_df = (\n",
    "    # Using the den_ndvi_cdc_gdf\n",
    "    den_ndvi_cdc_gdf\n",
    "    # Create a copy to avoid modifying the original data\n",
    "    .copy()\n",
    "    # Select the subet of columns needed\n",
    "    [['frac_veg', 'depression', 'all_mean_patch_size', 'all_edge_density', 'geometry']]\n",
    "    # Remove any rows with NaN VALUES\n",
    "    .dropna()\n",
    ")\n",
    "# Log transformation of depression data in the df\n",
    "# This is to help handle skewed data or effort to normalize it\n",
    "den_model_df['log_depression'] = np.log(den_model_df.depression)\n",
    "\n",
    "# Plot scatter matrix to identify variables that need transformation\n",
    "# Create new variable to save plots to\n",
    "den_scatter_matrix = (\n",
    "\n",
    "# Generate a scatter matrix (or pair plot)\n",
    "hvplot.scatter_matrix(\n",
    "    # Using model df\n",
    "    den_model_df\n",
    "    # Select columns to be plotted in the matrix\n",
    "    [[ \n",
    "        'all_mean_patch_size',\n",
    "        'all_edge_density',\n",
    "        'log_depression'\n",
    "    ]]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(den_scatter_matrix, 'den_scatter_matrix.html')  \n",
    "\n",
    "# Display the plots\n",
    "den_scatter_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select predictor and outcome variables\n",
    "# Define the predictor or indpendent variables\n",
    "X = den_model_df[['all_edge_density', 'all_mean_patch_size']]\n",
    "# Define the outcome variable or dependent variable\n",
    "y = den_model_df[['log_depression']]\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    # Specifiy that 33% of the data will be used for testing\n",
    "    X, y, test_size=0.33, \n",
    "    # Ensure that data is split randomly - the random split is reproducible\n",
    "    random_state=42)\n",
    "\n",
    "# Fit a linear regression\n",
    "#Create an instance of the linear regression model\n",
    "reg = LinearRegression()\n",
    "# Fit the training data to the linear regression model\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict depression values for the test dataset\n",
    "y_test['pred_depression'] = np.exp(\n",
    "    # Apply exponential function to predicted values to transform to original scale\n",
    "    reg.predict(X_test))\n",
    "# Apply exponential function to predicted values to transform to original scale\n",
    "y_test['depression'] = np.exp(y_test.log_depression)\n",
    "\n",
    "# Plot measured vs. predicted depression prevalence with a 1-to-1 line\n",
    "\n",
    "# Find max value of depression prevalence in the test dat to set the limits for the plot axes\n",
    "y_max = y_test.depression.max()\n",
    "\n",
    "# Create new variable to save plot to\n",
    "den_measured_v_predicted_depression = (\n",
    "(\n",
    "# Create scatterplot \n",
    " y_test.hvplot.scatter(\n",
    "        # X axis is actual depression prevalence and Y axis is predicted depression prevalence\n",
    "        x='depression', y='pred_depression',\n",
    "        # Label x axis\n",
    "        xlabel='Measured Depression Prevalence', \n",
    "        # Label y axis\n",
    "        ylabel='Predicted Depression Prevalence',\n",
    "        # Create title for plot\n",
    "        title='Linear Regression Performance - Testing Data'\n",
    "    ) \n",
    "    .opts(\n",
    "        # Scale both axes the same\n",
    "        aspect='equal', \n",
    "        # Set limits for the axes - scale according to range of actual depression values\n",
    "        xlim=(0, y_max), ylim=(0, y_max), \n",
    "        # Set size of the plot\n",
    "        height=500, width=600)\n",
    "    # Add a slope line and set color of line\n",
    ") * hv.Slope(slope=1, y_intercept=0).opts(color='black')\n",
    ")\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(den_measured_v_predicted_depression, 'den_measured_v_predicted_depression.html') \n",
    "\n",
    "# Display the plot \n",
    "den_measured_v_predicted_depression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model error for all census tracts\n",
    "# Apply exponential function to predicted values to transform to original scale\n",
    "den_model_df['pred_depression'] = np.exp(reg.predict(X))\n",
    "# Calculate model error for each Census tract, store computed errors in a new column\n",
    "den_model_df['err_depression'] = den_model_df['pred_depression'] - den_model_df['depression']\n",
    "\n",
    "# Create new variable to save the plot to\n",
    "den_model_error_chloropleth = (\n",
    "# Plot error geographically as a chloropleth\n",
    "(\n",
    "    # Color the chloropleth based on the model error\n",
    "    plot_chloropleth(den_model_df, color='err_depression', cmap='RdBu')\n",
    "    # Adjust the color scale/range for the model error\n",
    "    .redim.range(err_depression=(-.3, .3))\n",
    "    # Customize plot\n",
    "    .opts(\n",
    "        # Add a title\n",
    "        title= 'City of Denver - Model Errors for Predicted Depression Prevalence',\n",
    "        # Add a label for color bar\n",
    "        clabel= 'Model Error',\n",
    "        # Adjust size of plot\n",
    "        frame_width=600, \n",
    "        # Ensure aspect ratio equal (helps preserve the true shaps of census tracts)\n",
    "        aspect='equal')\n",
    ")\n",
    ")\n",
    "# Save the plot as html to be able to display online\n",
    "hv.save(den_model_error_chloropleth, 'den_model_error_chloropleth.html')  \n",
    "\n",
    "# Display the plot\n",
    "den_model_error_chloropleth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe and Interpret Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store variables to use in next notebook\n",
    "%store "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
